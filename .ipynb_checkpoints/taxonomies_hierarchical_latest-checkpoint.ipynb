{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mTjpKvEZwKhn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# Scores\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Ignoring Errors\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3,\n",
       "       'AACCGATGATTATTCTCAACTAACCACAAAGACATCGGCACCCTATACCTAATCTTTGGCGCATGAGCCGGTATAGTCGGTACAGCCCTCAGCTTACTTATCCGCGCAGAACTAGGCCAACCAGGAACCCTCCTAGGAGAC---GACCAAATCTATAACGTAATTGTCACCGCCCACGCTTTCGTAATAATCTTTTTCATAGTCATGCCAATCATAATCGGCGGCTTCGGCAACTGACTAGTCCCACTGATAATTGGTGCACCGGACATAGCATTCCCCCGCATAAATAACATAAGCTTCTGACTACTTCCTCCATCATTTTTACTTCTTCTAGCCTCTTCTACAGTCGAAGCAGGAGCAGGTACCGGATGAACCGTTTACCCGCCTCTAGCTGGCAACCTAGCACACGCTGGAGCATCAGTAGACCTAGCCATCTTCTCACTTCACCTAGCAGGTGTCTCCTCTATCCTAGGCGCAATCAACTTCATCACAACCGCCATCAACATAAAACCACCTGCCCTCTCACAATACCAAACTCCCCTATTCGTCTGATCCGTACTTATCACCGCTGTTCTATTACTCCTCTCACTTCCAGTCCTCGCTGCAGGCATCACCATGCTACTAACAGACCGAAATCTGAACACTACATTCTTCGATCCTGCTGGAGGAGGTGACCCAGTCCTGTACCAACATCTCTTTTGATTCTTCGGCCACCCAGAAGTCTACATCTTAATCTTACCAGGATTTGGAATCATCTCCCACGTAGTAACATACTACGCAGGTAAAAAAGAGCCATTCGGCTATATAGGAATAGTTTGAGCCATACTATCAATCGGATTCCTAGGCTTCATTGTTTGAGCCCACCACATATTCACCGTAGAAATGGACGTAGACACCCGAG-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------',\n",
       "       'Charadrius', 243, 275, 150, 230], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Aves.Cleaned.k1.csv\")\n",
    "# df[df.genus_name == 'Pterodroma']\n",
    "asdf = np.array(df)[2,:]\n",
    "# df\n",
    "asdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating Taxonomic Class:\n",
    "\n",
    "- If a sample is predicted true it will goes to predict subclasses, it will append 0 if it is estimated wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_val_score(k):\n",
    "    f1_scores_train, f1_scores_test = [], []\n",
    "    \n",
    "    data = combined_datas[str(k)]\n",
    "    X = np.array(data.iloc[:,2:]) # X is the barcode sequences\n",
    "    species = np.ravel(data.iloc[:,1])\n",
    "    y = np.ravel(data.iloc[:,0]) # y is the taxonomic classes\n",
    "    \n",
    "\n",
    "    kf = StratifiedKFold(10, random_state=0, shuffle=True)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        predictions_train, predictions_test = [], []\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        species_train, species_test = species[train_index], species[test_index]\n",
    "        \n",
    "        # Keeping Taxonomy Classes to Predict species\n",
    "        Aves_train = data.iloc[train_index,:][data.taxonomic_class == 'Aves']\n",
    "        Aves_test = data.iloc[test_index,:][data.taxonomic_class == 'Aves']\n",
    "        Chiroptera_train = data.iloc[train_index,:][data.taxonomic_class == 'Chiroptera']\n",
    "        Chiroptera_test = data.iloc[test_index,:][data.taxonomic_class == 'Chiroptera']\n",
    "        Rodentia_train = data.iloc[train_index,:][data.taxonomic_class == 'Rodentia']\n",
    "        Rodentia_test = data.iloc[test_index,:][data.taxonomic_class == 'Rodentia']\n",
    "        classes = {'Aves':[Aves_train, Aves_test], \"Chiroptera\":[Chiroptera_train, Chiroptera_test],\n",
    "                  \"Rodentia\":[Rodentia_train, Rodentia_test]}\n",
    "        \n",
    "        # Classifiers\n",
    "        linear_svm_taxonomy = Pipeline([['sc', StandardScaler()], ['clf', SVC(gamma=1/X_train.shape[0],\n",
    "                    kernel=\"linear\", probability=True, random_state=0)]])\n",
    "        linear_svm_taxonomy.fit(X_train, y_train)\n",
    "        \n",
    "        linear_svm_aves = Pipeline([['sc', StandardScaler()], ['clf', SVC(gamma=1/Aves_train.shape[0],\n",
    "                kernel=\"linear\", probability=True, random_state=0)]])\n",
    "        linear_svm_aves.fit(np.array(Aves_train.iloc[:,2:]), np.ravel(Aves_train.iloc[:,1]))\n",
    "        \n",
    "        linear_svm_chiroptera = Pipeline([['sc', StandardScaler()], ['clf', SVC(gamma=1/Chiroptera_train.shape[0],\n",
    "                kernel=\"linear\", probability=True, random_state=0)]])\n",
    "        linear_svm_chiroptera.fit(np.array(Chiroptera_train.iloc[:,2:]), np.ravel(Chiroptera_train.iloc[:,1]))\n",
    "            \n",
    "        linear_svm_rodentia = Pipeline([['sc', StandardScaler()], ['clf', SVC(gamma=1/Rodentia_train.shape[0],\n",
    "                kernel=\"linear\", probability=True, random_state=0)]])\n",
    "        linear_svm_rodentia.fit(np.array(Rodentia_train.iloc[:,2:]), np.ravel(Rodentia_train.iloc[:,1]))\n",
    "        \n",
    "        y_pred_train = linear_svm_taxonomy.predict(X_train)\n",
    "        y_pred_test = linear_svm_taxonomy.predict(X_test)\n",
    "        \n",
    "        \n",
    "        # Predict the Species\n",
    "        for idx in range(X_train.shape[0]):\n",
    "            if y_pred_train[idx] == 'Aves':\n",
    "                \n",
    "                y_pred_train_species = linear_svm_aves.predict(X_train[idx, :])\n",
    "                predictions_train.append(y_pred_train_species)\n",
    "                \n",
    "            elif y_pred_train[idx] == 'Chiroptera':\n",
    "                \n",
    "                y_pred_train_species = linear_svm_chiroptera.predict(X_train[idx, :])\n",
    "                predictions_train.append(y_pred_train_species)\n",
    "                \n",
    "            elif y_pred_train[idx] == 'Rodentia':\n",
    "                \n",
    "                y_pred_train_species = linear_svm_rodentia.predict(X_train[idx, :])\n",
    "                predictions_train.append(y_pred_train_species)\n",
    "            \n",
    "        for idx in range(X_test.shape[0]):\n",
    "            if y_pred_test[idx] == 'Aves':\n",
    "                \n",
    "                y_pred_test_species = linear_svm_aves.predict(X_test[idx, :])\n",
    "                predictions_test.append(y_pred_test_species)\n",
    "                \n",
    "            elif y_pred_test[idx] == 'Chiroptera':\n",
    "                \n",
    "                y_pred_test_species = linear_svm_chiroptera.predict(X_test[idx, :])\n",
    "                predictions_test.append(y_pred_test_species)\n",
    "                \n",
    "            elif y_pred_test[idx] == 'Rodentia':\n",
    "                \n",
    "                y_pred_test_species = linear_svm_rodentia.predict(X_test[idx, :])\n",
    "                predictions_test.append(y_pred_test_species)\n",
    "                \n",
    "                \n",
    "        f1_scores_train.append(f1_score(species_train, predictions_train, pos_label=None, average='micro'))\n",
    "        f1_scores_test.append(f1_score(species_test, predictions_test, pos_label=None, average='micro'))\n",
    "            \n",
    "            \n",
    "    \n",
    "    f1_scores_train = np.ravel(f1_scores_train)\n",
    "    f1_scores_test = np.ravel(f1_scores_test)\n",
    "    \n",
    "    return [(f1_scores_train.mean(), f1_scores_train.std()),\n",
    "            (f1_scores_test.mean(), f1_scores_test.std())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score Calculation For Species Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def species_score(data):\n",
    "#     species_f1_train = []\n",
    "#     species_f1_test = []\n",
    "\n",
    "#     X = np.array(data.iloc[:,2:])\n",
    "#     y = np.ravel(data.iloc[:,1])\n",
    "#     kf = StratifiedKFold(10, random_state=0, shuffle=True)\n",
    "    \n",
    "#     for train_index, test_index in kf.split(X, y):\n",
    "#         X_train, X_test = X[train_index], X[test_index]\n",
    "#         y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "#         linear_svm = Pipeline([['sc', StandardScaler()], ['clf', SVC(gamma=1/X_train.shape[0],\n",
    "#                     kernel=\"linear\", probability=True, random_state=0)]])\n",
    "#         linear_svm.fit(X_train, y_train)\n",
    "\n",
    "#         y_pred_train = linear_svm.predict(X_train)\n",
    "#         f1_micro_train = f1_score(y_train, y_pred_train, pos_label=None, average='micro')\n",
    "#         species_f1_train.append(f1_micro_train)\n",
    "          \n",
    "#         y_pred_test = linear_svm.predict(X_test)\n",
    "#         f1_micro_test = f1_score(y_test, y_pred_test, pos_label=None, average='micro')\n",
    "#         species_f1_test.append(f1_micro_test)\n",
    "\n",
    "#     species_f1_train = np.ravel(species_f1_train)\n",
    "#     species_f1_test = np.ravel(species_f1_test)\n",
    "#     return (species_f1_train.mean(), species_f1_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trained_model(data):\n",
    "#     X = np.array(data.iloc[:,2:])\n",
    "#     y = np.ravel(data.iloc[:,1])\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify=y)\n",
    "#     linear_svm = Pipeline([['sc', StandardScaler()], ['clf', SVC(gamma=1/X_train.shape[0],\n",
    "#                     kernel=\"linear\", probability=True, random_state=0)]])\n",
    "#     linear_svm.fit(X_train, y_train)\n",
    "#     return linear_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting and Merging Data & Species Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Cgv5IF4wKh-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'Aves.Cleaned.k2.csv' does not exist: b'Aves.Cleaned.k2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-4acc9786cc46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#     trained_taxonomic_class_models.setdefault(str(k), {})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mcsv_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}.Cleaned.k{}.csv\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mcsv_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Unnamed: 0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'nucleotides'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mtaxonomies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"taxonomic_class\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\huzeyfeayaz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\huzeyfeayaz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\huzeyfeayaz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\huzeyfeayaz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\huzeyfeayaz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'Aves.Cleaned.k2.csv' does not exist: b'Aves.Cleaned.k2.csv'"
     ]
    }
   ],
   "source": [
    "data_names = ['Aves', 'Chiroptera', 'Rodentia']\n",
    "combined_datas = {}\n",
    "# trained_taxonomic_class_models = {}\n",
    "for k in range(1,8):\n",
    "    before_combine_df = []\n",
    "#     trained_taxonomic_class_models.setdefault(str(k), {})\n",
    "    for data in data_names:\n",
    "        csv_file = pd.read_csv(\"{}.Cleaned.k{}.csv\".format(data, k))\n",
    "        csv_file = csv_file.drop(['Unnamed: 0', 'nucleotides'],1)\n",
    "        taxonomies = pd.DataFrame(np.ravel([data for i in range(csv_file.shape[0])]), columns = [\"taxonomic_class\"])\n",
    "        taxonomy_class_added = pd.concat([taxonomies, csv_file], axis=1)\n",
    "        before_combine_df.append(taxonomy_class_added)\n",
    "        \n",
    "#         model = trained_model(taxonomy_class_added)\n",
    "#         trained_taxonomic_class_models[str(k)][data] = model\n",
    "\n",
    "    combined_datas[str(k)] = pd.concat(before_combine_df, axis=0)\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(combined_datas['1'][combined_datas['1'].taxonomic_class == 'Aves'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting to Hierarchical Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 778744,
     "status": "error",
     "timestamp": 1577679159560,
     "user": {
      "displayName": "Huzeyfe Ayaz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mABLAzm5JK_CnqTUmdKH5HwVCZ4l0oXPSxpKTSz=s64",
      "userId": "09330556348955103282"
     },
     "user_tz": -180
    },
    "id": "iQVSRtTN2Hee",
    "outputId": "77ac189c-828f-4d43-9ea5-d33879c2108a"
   },
   "outputs": [],
   "source": [
    "hierarchical_scores = {}\n",
    "for k in range(1,8):\n",
    "    f1_scores_ = find_val_score(k)\n",
    "    hierarchical_scores[str(k)] = f1_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing The Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yxbn-Pg4wKiL"
   },
   "outputs": [],
   "source": [
    "with open('scores.db','wb') as score:\n",
    "    pickle.dump(hierarchical_scores, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 856672,
     "status": "ok",
     "timestamp": 1577679267650,
     "user": {
      "displayName": "Huzeyfe Ayaz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mABLAzm5JK_CnqTUmdKH5HwVCZ4l0oXPSxpKTSz=s64",
      "userId": "09330556348955103282"
     },
     "user_tz": -180
    },
    "id": "g7z8nxhnSkTs",
    "outputId": "51b92fd2-7e69-43ca-fdb2-66ec42698608"
   },
   "outputs": [],
   "source": [
    "print(hierarchical_scores)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "taxonomies_hierarchical.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
